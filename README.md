# Responsible Data Workshop Resources
This repository contains resources that are relevant to our workshop series on responsibly training foundation models.
If you are interested in contributing resources to this repository, please submit an [Issue](https://github.com/Responsible-Data-Workshop/resources/issues). 

### Upcoming Workshops
- [September 15th-16th @ ASU California Center](https://responsible-data-workshop.github.io/la2025/)
- [October 18th or 19th @ CSCW 2025](https://responsible-data-workshop.github.io/cscw2025/)


## Resources
### Ethical Considerations and Frameworks
- [A Taxonomy of Challenges to Curating Fair Datasets](https://proceedings.neurips.cc/paper_files/paper/2024/hash/b142e78db191e19b17e60c1425a28b52-Abstract-Datasets_and_Benchmarks_Track.html)
- [Ethical Considerations for Responsible Data Curation](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ad3ebc951f43d1e9ed20187a7b5bc4ee-Abstract-Datasets_and_Benchmarks.html)
- [The Dark Side of Dataset Scaling: Evaluating Racial Classification in Multimodal Models](https://dl.acm.org/doi/10.1145/3630106.3658968)
- [Consent in Crisis: The Rapid Decline of the AI Data Commons](https://arxiv.org/abs/2407.14933)
- [A Critical Analysis of the Largest Source for Generative AI Training Data: Common Crawl](https://dl.acm.org/doi/10.1145/3630106.3659033)
- [Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus](https://aclanthology.org/2021.emnlp-main.98.pdf)
- [Training Data for the Price of a Sandwich: Common Crawlâ€™s Impact on Generative AI](https://www.mozillafoundation.org/en/research/library/generative-ai-training-data/common-crawl/)
- [We Must Fix the Lack of Transparency Around the Data Used to Train Foundation Models](https://hdsr.mitpress.mit.edu/pub/xau9dza3/release/2)


### Background on Current Dataset Curation Practices
#### Overview
- [A Survey on Data Selection for Language Models](https://arxiv.org/abs/2402.16827)
- [Data Curation for LLMs](https://dcai.csail.mit.edu/2024/data-curation-llms/)
- [What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners' Perspective](https://dl.acm.org/doi/abs/10.1145/3691620.3695061)

#### Pre-Training Data
- [Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research](https://arxiv.org/abs/2402.00159)
#### Preference Data
- [Reinforcement Learning from Human Feedback](https://rlhfbook.com/)
   - [Section on Preference Data](https://rlhfbook.com/c/06-preference-data.html)
   - [Section on Constitutional AI & AI Feedback](https://rlhfbook.com/c/13-cai.html)
- [The Future of Open Human Feedback](https://arxiv.org/abs/2408.16961)
- [The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models](https://arxiv.org/abs/2404.16019)
